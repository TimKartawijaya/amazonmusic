{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File lastfm_9000_users.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f791979994dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Import main dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lastfm_9000_users.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TimGimi/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TimGimi/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TimGimi/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TimGimi/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TimGimi/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File lastfm_9000_users.csv does not exist"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "from math import log\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import implicit\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import savefig\n",
    "import time \n",
    "\n",
    "# Import main dataset\n",
    "df = pd.read_csv('lastfm_9000_users.csv', na_filter=False)\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_sparse_matrix and calculate_sparsity are functions that allow us to set up the dataset in sparse matrix form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix from dataframe object\n",
    "def create_sparse_matrix(data, user_user = True):\n",
    "    \"\"\"\n",
    "    Creates sparse matrix (csr_matrix) out of pandas dataframe.\n",
    "    \n",
    "    Parameters: \n",
    "    - data: Dataframe of user/artist data\n",
    "    - user_user: determines whether output will be for user-to-user or item-to-item collaborative filtering\n",
    "                 if user_user is True, then rows will be items and columns will be users\n",
    "    \n",
    "    Returns: \n",
    "    - plays_sparse: a sparse csr_matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Creating sparse matrix...\")\n",
    "    #grab unique users/artist IDS\n",
    "    users = list(np.sort(data.user_id.unique()))\n",
    "    artists = list(data.artist_mbid.unique())\n",
    "    plays = list(data.plays)\n",
    "\n",
    "    # user-user set-up\n",
    "    if (user_user == True):\n",
    "        rows = data.user_id.astype('category', categories=users).cat.codes\n",
    "        cols = data.artist_mbid.astype('category', categories=artists).cat.codes\n",
    "        plays_sparse = scipy.sparse.csr_matrix((plays, (rows, cols)), shape=(len(users),len(artists)))\n",
    "\n",
    "    #item-item set-up\n",
    "    else:    \n",
    "        rows = data.artist_mbid.astype('category', categories=artists).cat.codes\n",
    "        cols = data.user_id.astype('category', categories=users).cat.codes\n",
    "        plays_sparse = scipy.sparse.csr_matrix((plays, (rows, cols)), shape=(len(artists),len(users)))\n",
    "        \n",
    "    return plays_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sparsity of mnatrix\n",
    "def calculate_sparsity(M):\n",
    "    \"\"\"\n",
    "    Computes sparsity of matrix\n",
    "    \n",
    "    params:\n",
    "        M: matrix to be computed\n",
    "    \"\"\"\n",
    "    matrix_size = float(M.shape[0]*M.shape[1]) # Number of possible interactions in the matrix\n",
    "    num_plays = len(M.nonzero()[0]) # Number of items interacted with\n",
    "    sparsity = 100*(1 - float(num_plays/matrix_size))\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions are used to split the dataset into test/train/tune in various ways. \n",
    "make_train_all_user_pairs splits the data into a test and training set with a proportion taken over all users, while split_train_test_per_user makes sure that a certain proportion of each user is held off for the test set. \n",
    "\n",
    "split_train_test_per_user also allows for the option of k-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train, test using all user-artist pairs\n",
    "def make_train_all_user_pairs(data, test_pct):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        data: data set in csr_matrix format\n",
    "        test_pct: percentage to be test set\n",
    "    \"\"\"\n",
    "    # Create copies of dataset for training and test data\n",
    "    test = data.copy()\n",
    "    train = data.copy()\n",
    "    \n",
    "    #alter train data, masking/holding-out random user-pair values for some users\n",
    "    nonzero_idx = train.nonzero() #find indices in data where interaction exists\n",
    "    \n",
    "    \n",
    "    nonzero_pairs = zip(nonzero_idx[0], nonzero_idx[1]) #create pairs of (user, item) index\n",
    "    \n",
    "    # Determine how many user-pair values we need to mask, according to test_pct\n",
    "    random.seed(0) #for reproducibility\n",
    "    num_samples = int(np.ceil(test_pct * len(nonzero_pairs)))\n",
    "    \n",
    "    #Sample random number of user-item pairs without replacement\n",
    "    samples = random.sample(nonzero_pairs, num_samples) \n",
    "    print(type(samples))\n",
    "    \n",
    "    # Get user, item row and column indices\n",
    "    user_idx = [index[0] for index in samples] \n",
    "    item_idx = [index[1] for index in samples] \n",
    "    \n",
    "    # Mask the randomly chosen user-item pairs\n",
    "    train[user_idx,item_idx] = 0 \n",
    "    # Remove zeros in sparse arrays that was made previously\n",
    "    train.eliminate_zeros() \n",
    "    \n",
    "    return train, test, list(set(user_idx)), samples #output unique list of user rows that were altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train, test by user only with interactions#, with test size=total/k\n",
    "def split_train_test_per_user(data, k, interactions = 20,cross_valid= False):\n",
    "    \"\"\"\n",
    "    Create train matrix with masked values and dictionary of test values \n",
    "    \n",
    "    Parameters:\n",
    "    - data: csr_matrix, assuming matrix is user-user (item as rows, columns as users)\n",
    "    - test_pct: percentage of items to mask per user\n",
    "    \n",
    "    Output:\n",
    "    - train: masked matrix\n",
    "    - test: list of tuples of held out data ((user_idx, item_idx), plays)\n",
    "    \"\"\"\n",
    "    random.seed(0) #for reproducibility\n",
    "    \n",
    "    train = data.copy() #transpose to make procedure easier/more intuitive\n",
    "    \n",
    "    test = dict() #dict to keep track of masked user-item values\n",
    "    \n",
    "    user_count = 0\n",
    "    test_list=[]\n",
    "    train_list=[]\n",
    "    if cross_valid==True: #initialize\n",
    "        for i in range(k):\n",
    "            test_list.append(dict())\n",
    "            train_list.append(train)\n",
    "    \n",
    "    for user_idx in tqdm(range(train.get_shape()[0])):\n",
    "\n",
    "        # Get indices of interactions of this user\n",
    "        nonzero_idx = train[user_idx].nonzero()\n",
    "\n",
    "        # Only hold out users that have enough data (greater than interactions #)\n",
    "        if nonzero_idx[1].shape[0] >= interactions:\n",
    "            user_count += 1\n",
    "            # Create list of tuples: interaction index (row, col) with the number of plays\n",
    "            nonzero_pairs = [((user_idx, item_idx), train[user_idx,item_idx]) for item_idx in nonzero_idx[1]]\n",
    "\n",
    "            # Sort tuples by descending value\n",
    "            nonzero_sorted = sorted(nonzero_pairs, key = itemgetter(1), reverse = True)\n",
    "\n",
    "            # Get top interaction # values, then sample test_pct% randomly from subset\n",
    "            top_values = nonzero_sorted[0:interactions]\n",
    "\n",
    "            # Sample random number of item_indexes without replacement\n",
    "            num_samples = int(np.floor(interactions/float(k)))\n",
    "            if (cross_valid==False): \n",
    "                samples = random.sample(top_values, num_samples) \n",
    "\n",
    "                # Append user_idx, item_\n",
    "                test[user_idx] = [pair[0][1] for pair in samples]\n",
    "\n",
    "                # Mask the randomly chosen items of this user\n",
    "                for pair in samples:\n",
    "                    train[pair[0][0], pair[0][1]] = 0\n",
    "            \n",
    "            # Cross Validation Step\n",
    "            else:\n",
    "                for i in range(k):\n",
    "                    train = train_list[i]\n",
    "                    k_test=test_list[i]\n",
    "                    random.shuffle(top_values) \n",
    "                    samples=top_values[0:num_samples]\n",
    "                    top_values=top_values[num_samples:]\n",
    "                    # Append user_idx, item_\n",
    "                    k_test[user_idx] = [pair[0][1] for pair in samples]\n",
    "                    test_list[i]=k_test #update test\n",
    "                    # Mask the randomly chosen items of this user\n",
    "                    for pair in samples:\n",
    "                        train[pair[0][0], pair[0][1]] = 0\n",
    "                    train.eliminate_zeros()\n",
    "                    # Update train\n",
    "                    train_list[i]=train \n",
    "    if (cross_valid==False):\n",
    "        # Convert matrix back to initial shape\n",
    "        return train.T.tocsr(), test, user_count\n",
    "    else:\n",
    "        for i in range(k):\n",
    "            train_list[i]=train_list[i].T.tocsr()\n",
    "        # Convert matrix back to initial shape\n",
    "        return train_list, test_list, user_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many interactions are masked compared to previous dataset\n",
    "def pct_masked(original, altered):\n",
    "    altered_n = altered.nonzero()[0].shape[0]\n",
    "    original_n = original.nonzero()[0].shape[0]\n",
    "    return (original_n - altered_n)/float(altered_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Implementation\n",
    "\n",
    "Below is how we generated our baseline recommendations (taking the most popular artists across the entire dataset and recommending them to everyone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline model\n",
    "def baseline(k,user_items):\n",
    "    plays=user_items.toarray()\n",
    "    totalplays=np.sum(plays,axis=1)    \n",
    "    idx = (-totalplays).argsort()[:k]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation/Metrics\n",
    "\n",
    "The following are the functions we wrote to determine the NDCG/recall of the baseline, ALS, and KNN recommendations. \n",
    "\n",
    "auto_tune_parameter is a function written to determine the best hyperparameters to use for a given model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros_list(n):\n",
    "    listofzeros = [0] * n\n",
    "    return listofzeros\n",
    "\n",
    "def dcg_at_k(scores):\n",
    "    assert scores\n",
    "    return scores[0] + sum(sc / log(ind, 2) for sc, ind in zip(scores[1:], range(2, len(scores)+1)))\n",
    "\n",
    "def ndcg_at_k(predicted_scores, user_scores):\n",
    "    \"\"\"\n",
    "    predicted_scores: recommended k items from model\n",
    "    user_scores: held out items\n",
    "    \"\"\"\n",
    "    assert len(predicted_scores) == len(user_scores)\n",
    "\n",
    "    idcg = dcg_at_k(sorted(user_scores, reverse=True))\n",
    "    x = (dcg_at_k(predicted_scores) / idcg) if idcg > 0.0 else 0.0\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Used to evaluate model\n",
    "def evaluate(model, test, M, n_rec = 20):\n",
    "    \"\"\"\n",
    "    Calculate precision/recall\n",
    "    \n",
    "    parameters:\n",
    "    - model: fitted implicit model that will perform recommendations\n",
    "    - test: list containing tuples that are heldout for each user\n",
    "    - M: csr_matrix of item-users, used in fit\n",
    "    - n_rec: how many recommendations the system outputs\n",
    "    \n",
    "    returns:\n",
    "    - two numpy arrays containing precision and recall\n",
    "    \"\"\"\n",
    "    #TODO: Refactor NDCG and Recall, less dependent on each other\n",
    "    \n",
    "    # Transpose matrix to use for implicit's recommend() function\n",
    "    M_rec = M.T.tocsr() \n",
    "    \n",
    "    tp = float(0)\n",
    "    test_n = float(0)\n",
    "    print('Evaluating model...')\n",
    "    \n",
    "    ndcg = list()\n",
    "    \n",
    "    # Calculate true positives for each user, append results to list\n",
    "    for user, holdout_items in tqdm(test.items()):\n",
    "        \n",
    "        # Get list of item recs for each user\n",
    "        rec = model.recommend(user, M_rec, N=n_rec, filter_already_liked_items=True) #returns (item_id, score)\n",
    "        rec_items = [pair[0] for pair in rec] #get only item_id\n",
    "        test_n += len(holdout_items) #total number of heldout items\n",
    "        \n",
    "        # For NDCG\n",
    "        predicted_scores = zeros_list(n_rec)\n",
    "        user_scores = zeros_list(n_rec)\n",
    "        i = 0\n",
    "            \n",
    "        # Count true positives in recommended items\n",
    "        for item in holdout_items: \n",
    "            value = M[user,item]\n",
    "            user_scores[i] = value\n",
    "            i += 1\n",
    "            if item in rec_items:\n",
    "                predicted_scores[rec_items.index(item)] = value #if holdout items is in recommended\n",
    "                tp += 1\n",
    "        # Calculate NDCG\n",
    "        ndcg.append(ndcg_at_k(predicted_scores, user_scores))\n",
    "\n",
    "    recall = tp/test_n\n",
    "    return recall, np.mean(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to evaluate baseline model\n",
    "def evaluate_base(rec_items, test, M, n_rec = 20):\n",
    "    \"\"\"\n",
    "    Calculate recall\n",
    "    \n",
    "    parameters:\n",
    "    - model: fitted implicit model that will perform recommendations\n",
    "    - test: list containing tuples that are heldout for each user\n",
    "    - M: csr_matrix of item-users, used in fit\n",
    "    - n_rec: how many recommendations the system outputs\n",
    "    returns:\n",
    "    - numpy array containing recall\n",
    "    \"\"\"\n",
    "    # Transpose matrix to use for implicit's recommend() function\n",
    "    M_rec = M.T.tocsr()\n",
    "    \n",
    "    tp = float(0)\n",
    "    test_n = float(0)\n",
    "    rec_items = list(rec_items)\n",
    "    ndcg = list()\n",
    "\n",
    "    print('Evaluating model...')\n",
    "    # Calculate true positives for each user, append results to list\n",
    "\n",
    "    for user, holdout_items in tqdm(test.items()):\n",
    "        test_n += len(holdout_items)\n",
    "        # Count true positives in recommended items\n",
    "        predicted_scores = zeros_list(n_rec)\n",
    "        user_scores = zeros_list(n_rec)\n",
    "        i = 0\n",
    "        for item in holdout_items:\n",
    "            value = M[user,item]\n",
    "            user_scores[i] = value\n",
    "            i += 1\n",
    "            if item in rec_items:\n",
    "                predicted_scores[rec_items.index(item)] = value #if holdout items is in recommended\n",
    "                tp += 1\n",
    "\n",
    "        ndcg.append(ndcg_at_k(predicted_scores, user_scores))\n",
    "        \n",
    "    recall = tp/test_n\n",
    "    return recall,np.mean(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that identifies optimal parameter values given relevant models and arrays of parameters\n",
    "\n",
    "input: \n",
    "    - k: # of folds within the training set (split into tuning sets)\n",
    "    - interactions: size of recommendation list\n",
    "    - model: model that is being optimized   \n",
    "    - data: sparse user-item matrix\n",
    "    - param1: list of values to try for hyperparameter 1.\n",
    "    - param2: list of values to try for hyperparameter 2. \n",
    "    - param3: list of values to try for hyperparameter 3.\n",
    "    NOTE: if using KNN, there are 3 parameters. param2 is the integer used for k1; \n",
    "    only k and b are tested only param1 and param3 should be lists.\n",
    "    If using ALS, there are 2 parameters. both should be lists. \n",
    "    \n",
    "output:\n",
    "    - max_ndcg_list: a list of k tuples, one for each fold. \n",
    "        each tuple is in the form (max_ndcg,max_first_param,max_second_param,max_recall)\n",
    "        which records the best ndcg, and the two params that achieved it, \n",
    "        and the max_recall achieved (which may be from different param values).\n",
    "    - heatmap_list: a list of k heatmaps of the NDCG values for the two tested \n",
    "        parameters (one heatmap per fold). Useful for visualizations\n",
    "\"\"\"\n",
    "def auto_tune_parameter(k,interactions,model,data,param1,param2,param3=None):\n",
    "    # Train model\n",
    "    # Create list of MAX NDCG and Recall depending on # params\n",
    "    max_ndcg_list=[] #will end up being length k list of tuples of best param values\n",
    "    heatmap_list=[]\n",
    "    if param3==None: #for ALS\n",
    "        num_param=2\n",
    "        first_param=param1\n",
    "        second_param=param2\n",
    "    else: #for KNN\n",
    "        num_param=3\n",
    "        first_param=param1\n",
    "        second_param=param3\n",
    "    train_and_tune,test,user_count=split_train_test_per_user(data, k+1, interactions,cross_valid= False)\n",
    "    train_list, tune_list, user_count = split_train_test_per_user(train_and_tune.T.tocsr(),k,int(np.ceil(((k-1)/k)*interactions)),cross_valid=True)\n",
    "    #to be updated via max: to determine final params to use on test set \n",
    "    test_ndcg=0\n",
    "    test_first_param=first_param[0]\n",
    "    test_second_param=second_param[0]\n",
    "    #create recall/NDCG matrix storing for each combination of \n",
    "    for fold in range(k): #For each fold; there are k-1 folds within train_and_tune\n",
    "        ndcg_heatmap=[[0 for x in range(len(second_param))] for y in range(len(first_param))]\n",
    "        print(ndcg_heatmap)\n",
    "        train=train_list[fold]\n",
    "        tune=tune_list[fold]\n",
    "        max_first_param=first_param[0] #initialize best value of first_param for this fold\n",
    "        max_second_param=second_param[0] #initialize best value of second_param for this fold\n",
    "        max_recall=0\n",
    "        max_ndcg=0\n",
    "        value1_index=0 #index for heatmap\n",
    "        print(\"Fitting fold number...\",fold)\n",
    "        for value1 in first_param:\n",
    "            value2_index=0\n",
    "            for value2 in second_param:\n",
    "                if num_param==2:\n",
    "                    print(\"Trying \",(value1,value2))\n",
    "                    usemodel=model(value1,value2)\n",
    "                if num_param==3:\n",
    "                    print(\"Trying \",(value1,param2,value2))\n",
    "                    usemodel=model(value1,param2,value2)\n",
    "                usemodel.fit(train, show_progress=False)\n",
    "                recall,ndcg = evaluate(usemodel,tune,data)\n",
    "                print(value1_index,value2_index)\n",
    "                ndcg_heatmap[value1_index][value2_index]=ndcg #update heatmap \n",
    "                #recall_list.append(recall)\n",
    "                #update maximum values\n",
    "                max_recall=max(max_recall,recall)\n",
    "                if ndcg>max_ndcg: \n",
    "                    max_ndcg=ndcg\n",
    "                    max_first_param=value1\n",
    "                    max_second_param=value2\n",
    "                value2_index=value2_index+1\n",
    "            value1_index=value1_index+1    \n",
    "        max_ndcg_list.append([max_ndcg,max_first_param,max_second_param,max_recall])\n",
    "        if max_ndcg>test_ndcg:\n",
    "            print(\"Fold \",fold,\" beat the record for ncdg!\")\n",
    "            print(\"New best ndcg is \",max_ndcg)\n",
    "            print(\"New best params are \",(max_first_param,max_second_param))\n",
    "            test_ndcg=max_ndcg\n",
    "            test_first_param=max_first_param\n",
    "            test_second_param=max_second_param\n",
    "        heatmap_list.append(ndcg_heatmap)\n",
    "        print(\"end of fold---------------------------\")\n",
    "\n",
    "    #Now, test_first_param and test_second_param should be optimized\n",
    "    if num_param==2:\n",
    "        usemodel=model(test_first_param,test_second_param)\n",
    "    if num_param==3:\n",
    "        usemodel=model(test_first_param,param2,test_second_param)\n",
    "    usemodel.fit(train_and_tune,show_progress=True)\n",
    "    final_recall,final_ndcg = evaluate(usemodel,test,data)\n",
    "    \n",
    "    print(\"The recall on the test set is \", final_recall,\", after hyperparameter optimization\")\n",
    "    print(\"The ndcg on the test set is \",final_ndcg,\", after hyperparameter optimization\")\n",
    "    \n",
    "    return max_ndcg_list,heatmap_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script\n",
    "\n",
    "#### 1. Setup: Create sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_sparse_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1a85e733489c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplays_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Matrix Sparsity:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_sparsity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplays_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_sparse_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "#create sparse matrix\n",
    "plays_sparse = create_sparse_matrix(df).astype('float')\n",
    "print('Matrix Sparsity:', calculate_sparsity(plays_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a224034242426ab7aff074365bc980"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of original data masked: 0.06548419166887459\n",
      "Users masked: 8980\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "train, test, user_count = split_train_test_per_user(plays_sparse, 3, 10)\n",
    "print(\"Percentage of original data masked:\", pct_masked(plays_sparse, train))\n",
    "print(\"Users masked:\", user_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based (ALS)\n",
    "\n",
    "Here we run the model-based ALS Matrix Factorization and display the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:05<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1bd81d5179409cb26061a30e874f07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall: 22.178916109873796 %\n",
      "Average NDCG: 12.66723278283797 %\n"
     ]
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(50)\n",
    "\n",
    "# Train model\n",
    "print(\"Fitting model...\")\n",
    "model.fit(train, show_progress=True)\n",
    "\n",
    "# Compute and output recall and NDCG\n",
    "recall, ndcg = evaluate(model, test, plays_sparse)\n",
    "print(\"Recall:\",recall*100,'%')\n",
    "print(\"Average NDCG:\",ndcg*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors (Item-Based)\n",
    "\n",
    "Here we run the KNN and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/47102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47102/47102 [00:00<00:00, 86340.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d7be2b41ea4f6bb5267eeee879912f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall: 3.103192279138827 %\n",
      "Average NDCG: 1.6345120853324613 %\n"
     ]
    }
   ],
   "source": [
    "model_knn = implicit.nearest_neighbours.BM25Recommender()\n",
    "\n",
    "# Train Model\n",
    "print(\"Fitting model...\")\n",
    "model_knn.fit(train, show_progress=True)\n",
    "\n",
    "# Compute and output recall and NDCG\n",
    "recall, ndcg = evaluate(model_knn, test, plays_sparse)\n",
    "print(\"Recall:\",recall*100,'%')\n",
    "print(\"Average NDCG:\",ndcg*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline\n",
    "\n",
    "Here we run baseline and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up baseline model\n",
    "user_items = plays_sparse.T.tocsr()\n",
    "rec_items=baseline(20,user_items)\n",
    "\n",
    "# Compute and output recall and NDCG\n",
    "recall,ndcg = evaluate_base(rec_items,test,plays_sparse)\n",
    "print(\"Recall:\",recall*100,'%')\n",
    "print(\"Average NDCG per User:\",ndcg*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and Parameter Tuning (k-fold)\n",
    "\n",
    "In this section, we use k-fold cross validation to tune hyperparameters and evaluate our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fdaa12cdf64ad9bbf1ec00fbdbf4d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation test\n",
    "k=5\n",
    "train_list, test_list, user_count = split_train_test_per_user(plays_sparse,k,20,cross_valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and tune ALS\n",
    "\n",
    "Tuning two parameters: number of latent factors and the regularization factor. \n",
    "\n",
    "For latent factors, we try values [10,20,30,40,50,60]\n",
    "\n",
    "For regularization factors, we try [.01,.03,.05,.07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model=implicit.als.AlternatingLeastSquares\n",
    "ndcg_list,heatmap_list=auto_tune_parameter(4,20,model,plays_sparse,[10,20,30,40,50,60],[.01,.03,.05,.07],param3=None)\n",
    "stop = time.time()\n",
    "total = stop-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot heatmap of parameter tuning results\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.heatmap(heatmap_list[2], \n",
    "            xticklabels=['0.01','0.03','0.05','0.07'], \n",
    "            yticklabels=['10','20','30','40','50','60'], \n",
    "            cbar_kws={'label':'NDCG Score'})\n",
    "plt.ylabel(\"Number of Latent Factors\")\n",
    "plt.xlabel(\"Regularization Factor\")\n",
    "plt.title(\"ALS NDCG scores according to Model Parameters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyze the scalability of ALS by looking at datasets with 9k, 20k, 60k, and 150k users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following block imports larger datasets for scaling tests, these expanded CSVs are not available in the repo\n",
    "files9k = pd.read_csv('lastfm_9000_users.csv', na_filter=False)\n",
    "files20k = pd.read_csv('lastfm_20k_users.csv', na_filter=False)\n",
    "files60k = pd.read_csv('lastfm_60k_users.csv', na_filter=False)\n",
    "files150k = pd.read_csv('lastfm_150k_users.csv', na_filter=False)\n",
    "files40k = get_users(files150k, 40000)\n",
    "files = [files9k, files20k, files40k, files60k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the recall and ndcg using optimal parameters for the ALS model on different dataset sizes\n",
    "size = [9000, 20000, 40000, 60000]\n",
    "ndcg_size = []\n",
    "recall_size = []\n",
    "for i in files:\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=30, regularization=0.01)\n",
    "\n",
    "    #create sparse matrix\n",
    "    plays_sparse = create_sparse_matrix(i).astype('float')\n",
    "    print('Matrix Sparsity:', calculate_sparsity(plays_sparse))\n",
    "\n",
    "    train, test, user_count = split_train_test_per_user(plays_sparse, 4, 20)\n",
    "\n",
    "    # train model \n",
    "    print(\"Fitting model...\")\n",
    "    model.fit(train, show_progress=True)\n",
    "\n",
    "    recall, ndcg = evaluate(model, test, plays_sparse)\n",
    "    print(\"Recall:\",recall*100,'%')\n",
    "    print(\"Average NDCG:\",ndcg*100,'%')\n",
    "    recall_size.append(recall)\n",
    "    ndcg_size.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot scalability of ALS model\n",
    "ndcg_size_df = pd.DataFrame({'N':size,\n",
    "                       'NDCG': ndcg_size})\n",
    "g = sns.pointplot(x='N', y='NDCG', data=ndcg_size_df)\n",
    "plt.title('NDCG by Input Size for ALS')\n",
    "plt.xlabel('Number Of Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyze the catalog coverage of the ALS model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate catalog coverage of ALS model with optimal parameters\n",
    "model = implicit.als.AlternatingLeastSquares(factors=30, regularization=0.01)\n",
    "model.fit(plays_sparse)\n",
    "users = list(df.user_id.unique())\n",
    "catalog = []\n",
    "for i in range(0,len(users)):\n",
    "    for x,y in model.recommend(i,plays_sparse.T.tocsr(), N=20, filter_already_liked_items=True):\n",
    "        if x not in catalog:\n",
    "            catalog.append(x)\n",
    "print('Catalog Coverage is', len(catalog)/plays_sparse.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Tune KNN \n",
    "\n",
    "Tuning two parameters: K and B. \n",
    "\n",
    "For K, we try values [200,400,600,800,1000]\n",
    "\n",
    "For K1, we stick to default value of 1.2\n",
    "\n",
    "For B, we try [0,0.5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tune KNN to identify the best parameters\n",
    "model=implicit.nearest_neighbours.BM25Recommender\n",
    "max_ndcg_list, heatmap_list = auto_tune_parameter(4,20,model,plays_sparse,[200,400,600,800,1000],1.2,[0,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot heatmap of parameter tuning results\n",
    "sns.heatmap(heatmap_list[1], \n",
    "            yticklabels=['1000', '800', '600', '400', '200'], \n",
    "            xticklabels=[0,0.5,1],\n",
    "            cbar_kws={'label': 'NDCG Score'})\n",
    "plt.xlabel('B')\n",
    "plt.ylabel('Number of Neighbors')\n",
    "plt.title('KNN Parameter Tuning With NDCG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the recall and ndcg using optimal parameters for the ALS model on different dataset sizes\n",
    "size = [9000, 20000, 40000, 60000]\n",
    "ndcg_size_knn = []\n",
    "recall_size_knn = []\n",
    "for i in files:\n",
    "    model = implicit.nearest_neighbours.BM25Recommender(K=400, K1=1.2, B=0)\n",
    "\n",
    "    #create sparse matrix\n",
    "    plays_sparse = create_sparse_matrix(i).astype('float')\n",
    "    print('Matrix Sparsity:', calculate_sparsity(plays_sparse))\n",
    "\n",
    "    train, test, user_count = split_train_test_per_user(plays_sparse, 4, 20)\n",
    "\n",
    "    # train model \n",
    "    print(\"Fitting model...\")\n",
    "    model.fit(train, show_progress=True)\n",
    "\n",
    "    recall, ndcg = evaluate(model, test, plays_sparse)\n",
    "    print(\"Recall:\",recall*100,'%')\n",
    "    print(\"Average NDCG:\",ndcg*100,'%')\n",
    "    recall_size_knn.append(recall)\n",
    "    ndcg_size_knn.append(ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyze the scalability of the KNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot scalability of KNN model\n",
    "ndcg_size_knn_df = pd.DataFrame({'N':size,\n",
    "                       'NDCG': ndcg_size_knn})\n",
    "g = sns.pointplot(x='N', y='NDCG', data=ndcg_size_knn_df)\n",
    "plt.title('NDCG by Input Size for KNN')\n",
    "plt.xlabel('Number Of Users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyze the catalog coverage of the KNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate catalog coverage of KNN model with optimal parameters\n",
    "model = implicit.nearest_neighbours.BM25Recommender(K=400, K1=1.2, B=0)\n",
    "model.fit(plays_sparse)\n",
    "users = list(df.user_id.unique())\n",
    "catalog = []\n",
    "for i in range(0,len(users)):\n",
    "    for x,y in model.recommend(i,plays_sparse.T.tocsr(), N=20, filter_already_liked_items=True):\n",
    "        if x not in catalog:\n",
    "            catalog.append(x)\n",
    "print('Catalog Coverage is', len(catalog)/plays_sparse.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
